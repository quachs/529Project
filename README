CECS 429/529 Project Milestone 2

Team Members:
Sandra Kramlich
Sylvia Quach
Sean Vidal

Goal: Index a user-provided corpus on disk using the SPIMI strategy. 
Present the user with a GUI that allows them to execute boolean or 
ranked queries from a selected on-disk corpus.

Sub-goals: 
1. Write the KGramIndex associated with this index to disk.
2. Write the Soundex associated with this index to disk.
3. Provide the user the ability to rank relevant documents based 
	on one of four document-scoring strategies.
4. Apply spelling correction to query literals for both boolean 
	and ranked queries. 

----------------------------------------------------------------

General Program Flow:

// If User Wants to Create an On-disk Index
1. User has a choice of creating an on-disk index or querying an existing on-disk index
2. User clicks "Index a Corpus"
3. A file chooser allows the user to navigate to their corpus of choice.
4. Program indexes all terms in a corpus, building a dictionary that maps
	terms to on-disk positional posting lists.  Note that if a corpus
	contains documents with an author filed, the automatically-generated
	on-disk soundex will be populated.  Otherwise, it will remain empty.
5. Program displays a dialog box with the text "Indexing is finished"
6. User clicks "Ok"
7. Program terminates

// If User Wants to Execute Boolean Queries
2a. User clicks "Process queries"
3a. A file choose allows the user to navigate to their on-disk index of choice.
	Note that the folder must be the same as the corpus.  For example,
	if the indexed corpus was at folder ".../myCorpus/", then the user
	must also use ".../myCorpus/" as their index location and not the
	folder ".../myCorpus/Indexes".  An attempt to use the latter filepath
	will throw an exception
4a. Program prompts user to select between boolean and ranked retrieval
5a. User clicks "Boolean Retrieval"
6a. Program displays query GUI.
7a. User enters a boolean query into the GUI text field
8a. Program displays a list of documents that match query
9a. User double-clicks on one of the document titles
10a. Program displays document in its entirety
11a. Return to step 6a or click [X] in top-right corner of window to terminate program

// If User Wants to Execute Ranked Queries
5a-b. User clicks "Ranked Retrieval"
6a-b. User clicks one of four document scoring formulas ("Default," "Traditional," etc.)
7a-b. User enters a ranked query into the GUI text field
8a-b. Program displays a list of the top 10 most relevant documents,
	ordered from most relevant to least relevant.
9a-b. Return to step 9a

// If User Wants to Stem a Token
6a-c. User enters token in text box and clicks "Stem" button
7a-c. Program displays stemmed term in a dialog box
8a-c. User clicks "OK" button
9a-c. Return to step 6a

// If User Wants to Index a New Directory
6a-d. User clicks "Index new directory" button
7a-d. Return to step 3

// If user Wants to View Corpus Vocabulary
6a-e. User clicks "Print Vocabulary" button
7a-e. Program displays all terms stored in index in alphabetical order
8a-e. return to step 6a

----------------------------------------------------------------

******** Boolean Queries: ********

AND queries -> [query literal | wildcard query | near query | phrase query]+
OR queries -> [AND query]+
AUTHOR queries -> [query literal]
	NOTE: "author query" option must be selected from drop down menu

** Literals/Queries:
query literal - a standard, one-word term
wildcard query - a one-word term with leading, trailing, or embedded * characters
near query - a literal of the form [term1] near\[k] [term2]
phrase query - a sequence of terms enclosed in double quotes

Types of user queries that will not work:

... [wildcard literal] near\[k] [query literal] ...
... [query literal] near\[k] [wildcard literal] ...
... [wildcard literal] near\[k] [wildcard literal] ...

In other words, wildcard queries can not be embedded within near queries.

** A note on spelling correction:
Spelling correction works on all query literals except those that include phrases.

----------------------------------------------------------------

******** Ranked Queries ********
Literals/Queries:
query literal - a standard, one-word term
wildcard query - a one-word term with leading, trailing, or embeded * characters.

** A note on discrepancies between this milestone's document scoring and the demo project:
There is a difference between the size of the respective indeces between the two projects.
A possible result is the way both project's appear to index hyphenated tokens: the demo project
appears to perform some additional processing on the token on the right-hand-side of a hyphen
(where the form of a hyphenated token is [l.h.s.]-[r.h.s]).  The processing seems to occur on 
tokens with suffixes that end in -er, -ed, -eed, -ning, etc.  A reasonable guess is that a 
different stemming algorithm than the one implemented in this milestone's is being run on 
these right-hand-side tokens before indexing.

The boolean result sizes of affected terms tend to be larger in this milestone than the
result sizes of the same term in the demo.  While not a significant issue in any given boolean 
search, this discrepancy in sizes directly affects the document frequency and term frequency values needed 
to execute a successful ranked query.  Ranked queries that only use unaffected terms tend to generate 
ranked results comparable across both projects.  Unfortunately, this issue was unable to be resolved
by the milestone deadline and remains an outstanding issue.    

----------------------------------------------------------------

External software used:

Snowball software - made available under the 3-clause BSD License -
	http://snowball.tartarus.org/license.html
Snowball, including Porter2 (English) stemmer, is available at the following:  
	http://snowball.tartarus.org/download.html
GSON - made available under Apache LICENSE, which can be found in Git repository 

----------------------------------------------------------------

References:
 
C.D. Manning et al., Introduction to Information Retrieval, Online Edition
Cambridge University Press, 2009, pp. 11, 64;
https://nlp.stanford.edu/IR-book/pdf/irbookonlinereading.pdf

https://docs.oracle.com/javase/7/docs/api/java/util/ArrayList.html
https://docs.oracle.com/javase/7/docs/api/java/lang/String.html#split(java.lang.String)
https://docs.oracle.com/javase/tutorial/java/javaOO/constructors.html
https://docs.oracle.com/javase/7/docs/api/java/lang/String.html#startsWith(java.lang.String)
https://docs.oracle.com/javase/7/docs/api/java/lang/String.html#endsWith(java.lang.String)
https://docs.oracle.com/javase/7/docs/api/java/lang/String.html#replaceAll(java.lang.String,%20java.lang.String)
https://docs.oracle.com/javase/7/docs/api/java/lang/Double.html
https://docs.oracle.com/javase/8/docs/api/java/util/Scanner.html
//https://docs.oracle.com/javase/7/docs/api/java/lang/Comparable.html

[NOTE: This reference list is not exhaustive; 
additional references can be found within this project's code]
